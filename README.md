# Ecommerce Analytics Pipeline

A scalable, containerized ETL pipeline that ingests ecommerce datasets, loads raw data into PostgreSQL, and computes analytics tables with Apache Sparkâ€”all orchestrated in Docker.

---

## ğŸ“¦ Project Structure
ecommerce-analytics-pipeline/
â”œâ”€â”€ data/ 
â”‚   â”œâ”€â”€ raw/ #Raw data files (csv)
â”‚   â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”‚   â”œâ”€â”€ olist_orders_dataset.csv
â”‚   â”‚   â”œâ”€â”€ olist_order_items_dataset.csv
â”‚   â”‚   â””â”€â”€ olist_products_dataset.csv
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ streaming/
â”‚   â””â”€â”€ warehouse/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â””â”€â”€ data_loader.py #Loads CSVs to PostgreSQL
â”‚   â”œâ”€â”€ load/
â”‚   â””â”€â”€ transform/
â”‚       â””â”€â”€ spark_etl.py # ETL and analytics job
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01_create_schemas.sql
â”œâ”€â”€ docker-compose.yml #Service definition
â”œâ”€â”€ .env # Environment variables (DB creds)
â””â”€â”€ README.md


---

## ğŸš€ Quick Start

### 1. Clone This Repository

git clone https://github.com/1stEsper/ecommerce-analytics-pipeline.git
cd ecommerce-analytics-pipeline


### 2. Place Data Files

Copy your raw Olist CSV files into `data/raw/` (or as needed based on your pipeline).

### 3. Set Up Environment Variables

Create a `.env` file:

POSTGRES_DB=ecommerce_db
POSTGRES_USER=ecommerce_user
POSTGRES_PASSWORD=ecommerce_pass

### 4. Build and Start Docker Services

docker-compose up -d


Services started:
- PostgreSQL (`ecommerce_postgres`)
- pgAdmin for DB management (`ecommerce_pgadmin`)
- Redis (for streaming)
- Apache Spark Master & Workers
- Jupyter notebook server

### 5. Load Raw Data into PostgreSQL

Run the data loader (from the host):

docker exec ecommerce_spark_master spark-submit
--master spark://spark-master:7077
--deploy-mode client
/opt/spark-apps/extract/data_loader.py


### 6. Run the ETL Pipeline

docker exec ecommerce_spark_master spark-submit
--master spark://spark-master:7077
--deploy-mode client
/opt/spark-apps/transform/spark_etl.py


---

## ğŸ§© Whatâ€™s Inside?

- **data_loader.py**: Reads CSVs, loads to PostgreSQL (`raw_data` schema)
- **spark_etl.py**: Reads `raw_data`, computes key analytics, writes to `staging` and `analytics` schemas
- **docker-compose.yml**: All services defined for orchestration
- **src/**: All pipeline and helper code modularized

---

## ğŸ“Š Inspect Results

- Use pgAdmin (http://localhost:5050) or psql to inspect data, run queries, and export results:
  - `raw_data.customers`, `staging.customer_metrics`, `analytics.daily_sales`, etc.

---

## ğŸ“ License

MIT License (see [LICENSE](LICENSE) file)

---

## âœ¨ Credits

- [Olist Ecommerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
