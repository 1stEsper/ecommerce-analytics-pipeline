# Ecommerce Analytics Pipeline

A scalable, containerized ETL pipeline that ingests ecommerce datasets, loads raw data into PostgreSQL, and computes analytics tables with Apache Sparkâ€”all orchestrated in Docker.

---

## ğŸ“¦ Project Structure
```
ecommerce-analytics-pipeline/
â”œâ”€â”€ data/ 
â”‚ Â  â”œâ”€â”€ raw/ #Fichiers de donnÃ©es brutes (csv)
â”‚ Â  â”‚ Â  â”œâ”€â”€ olist_customers_dataset.csv
â”‚ Â  â”‚ Â  â”œâ”€â”€ olist_orders_dataset.csv
â”‚ Â  â”‚ Â  â”œâ”€â”€ olist_order_items_dataset.csv
â”‚ Â  â”‚ Â  â””â”€â”€ olist_products_dataset.csv
â”‚ Â  â”œâ”€â”€ processed/
â”‚ Â  â”œâ”€â”€ streaming/
â”‚ Â  â””â”€â”€ warehouse/
â”œâ”€â”€ src/
â”‚ Â  â”œâ”€â”€ extract/
â”‚ Â  â”‚ Â  â””â”€â”€ data_loader.py #Charge les CSV dans PostgreSQL
â”‚ Â  â”œâ”€â”€ load/
â”‚ Â  â””â”€â”€ transform/
â”‚ Â  Â  Â  â””â”€â”€ spark_etl.py # ETL et job d'analyse
â”œâ”€â”€ sql/
â”‚ Â  â””â”€â”€ init/
â”‚ Â  Â  Â  â””â”€â”€ 01_create_schemas.sql
â”œâ”€â”€ docker-compose.yml #DÃ©finition des services
â”œâ”€â”€ .env # Variables d'environnement (DB creds)
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Clone This Repository

```
git clone https://github.com/1stEsper/ecommerce-analytics-pipeline.git
cd ecommerce-analytics-pipeline
```

### 2. Place Data Files

Copy your raw Olist CSV files into `data/raw/` (or as needed based on your pipeline).

### 3. Set Up Environment Variables

Create a `.env` file:
```
POSTGRES_DB=ecommerce_db
POSTGRES_USER=ecommerce_user
POSTGRES_PASSWORD=ecommerce_pass
```

### 4. Build and Start Docker Services
```
docker-compose up -d
```


Services started:
- PostgreSQL (`ecommerce_postgres`)
- pgAdmin for DB management (`ecommerce_pgadmin`)
- Redis (for streaming)
- Apache Spark Master & Workers
- Jupyter notebook server

### 5. Load Raw Data into PostgreSQL

Run the data loader (from the host):
```
docker exec ecommerce_spark_master spark-submit
--master spark://spark-master:7077
--deploy-mode client
/opt/spark-apps/extract/data_loader.py
```

### 6. Run the ETL Pipeline
```
docker exec ecommerce_spark_master spark-submit
--master spark://spark-master:7077
--deploy-mode client
/opt/spark-apps/transform/spark_etl.py
```

---

## ğŸ§© Whatâ€™s Inside?

- **data_loader.py**: Reads CSVs, loads to PostgreSQL (`raw_data` schema)
- **spark_etl.py**: Reads `raw_data`, computes key analytics, writes to `staging` and `analytics` schemas
- **docker-compose.yml**: All services defined for orchestration
- **src/**: All pipeline and helper code modularized

---

## ğŸ“Š Inspect Results

- Use pgAdmin (http://localhost:5050) or psql to inspect data, run queries, and export results:
  - `raw_data.customers`, `staging.customer_metrics`, `analytics.daily_sales`, etc.

---

## ğŸ“ License

MIT License (see [LICENSE](LICENSE) file)

---

## âœ¨ Credits

- [Olist Ecommerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
